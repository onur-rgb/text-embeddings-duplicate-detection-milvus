{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Necessary Libraries\n",
    "We begin by importing the required Python libraries for data analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\onur_\\anaconda3\\envs\\home_project\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n",
    "Next, we load our dataset into a Pandas DataFrame for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('job_posting_short.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Overview\n",
    "Let's start by getting a high-level overview of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Id</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>SOC Code</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Qualification</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Job Opening Date</th>\n",
       "      <th>Job Closing Date</th>\n",
       "      <th>Status</th>\n",
       "      <th>Website Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>660d47be5c2db28218b65ad0df9965a2</td>\n",
       "      <td>Patient Care Associate, 32 hrs/wk, Night Shift...</td>\n",
       "      <td>31-1014.00</td>\n",
       "      <td>&lt;br/&gt; &lt;br/&gt;&lt;b&gt;Summary&lt;/b&gt;&lt;br/&gt; &lt;br/&gt;Provide di...</td>\n",
       "      <td>Partners Urgent Care</td>\n",
       "      <td>[Patient Care, Nursing]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Charlestown</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>2129.0</td>\n",
       "      <td>2021-07-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>http://partnersurgentcare.org/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>771a3aa4bc17d7bd51b2eb2c9e823223</td>\n",
       "      <td>Global Marketing Manager</td>\n",
       "      <td>11-2021.00</td>\n",
       "      <td>&lt;p&gt;Find what drives you on a team with a more ...</td>\n",
       "      <td>Danaher Corporation</td>\n",
       "      <td>[Global Marketing, Integrated Marketing, Field...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Westborough</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>1581.0</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>http://www.danaher.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>572ee827c4d17d2cb0b460620f54208f</td>\n",
       "      <td>Housekeeper</td>\n",
       "      <td>37-1011.00</td>\n",
       "      <td>&lt;!--/.col-xs-12--&gt;&lt;br/&gt;&lt;section&gt;&lt;br/&gt; &lt;br/&gt;&lt;no...</td>\n",
       "      <td>Brightview Senior Living</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North Andover</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>1845.0</td>\n",
       "      <td>2021-09-08</td>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>www.brightviewseniorliving.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ec13e41aca8d302b2659a3290be93723</td>\n",
       "      <td>Cisco Voice Engineer</td>\n",
       "      <td>17-2199.00</td>\n",
       "      <td>&lt;br/&gt; &lt;br/&gt;VOICE ENGINEER&lt;br/&gt; &lt;br/&gt; &lt;b&gt;Job fu...</td>\n",
       "      <td>Softworld</td>\n",
       "      <td>[c, VOIP, Cisco, MS Office tools, Genesys, SIP...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dorchester</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>2121.0</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>2021-09-16</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>http://www.softworldinc.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c6752d3d66618756e866128a1e3ed5bb</td>\n",
       "      <td>Contract Administrator II</td>\n",
       "      <td>11-3061.00</td>\n",
       "      <td>&lt;br/&gt; &lt;br/&gt;     Job Description    &lt;br/&gt; &lt;br/&gt;...</td>\n",
       "      <td>Artech Information Systems LLC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marlborough</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>http://www.artech.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Job Id  \\\n",
       "0  660d47be5c2db28218b65ad0df9965a2   \n",
       "1  771a3aa4bc17d7bd51b2eb2c9e823223   \n",
       "2  572ee827c4d17d2cb0b460620f54208f   \n",
       "3  ec13e41aca8d302b2659a3290be93723   \n",
       "4  c6752d3d66618756e866128a1e3ed5bb   \n",
       "\n",
       "                                           Job Title    SOC Code  \\\n",
       "0  Patient Care Associate, 32 hrs/wk, Night Shift...  31-1014.00   \n",
       "1                           Global Marketing Manager  11-2021.00   \n",
       "2                                        Housekeeper  37-1011.00   \n",
       "3                               Cisco Voice Engineer  17-2199.00   \n",
       "4                          Contract Administrator II  11-3061.00   \n",
       "\n",
       "                                     Job Description  \\\n",
       "0  <br/> <br/><b>Summary</b><br/> <br/>Provide di...   \n",
       "1  <p>Find what drives you on a team with a more ...   \n",
       "2  <!--/.col-xs-12--><br/><section><br/> <br/><no...   \n",
       "3  <br/> <br/>VOICE ENGINEER<br/> <br/> <b>Job fu...   \n",
       "4  <br/> <br/>     Job Description    <br/> <br/>...   \n",
       "\n",
       "                     Company Name  \\\n",
       "0            Partners Urgent Care   \n",
       "1             Danaher Corporation   \n",
       "2        Brightview Senior Living   \n",
       "3                       Softworld   \n",
       "4  Artech Information Systems LLC   \n",
       "\n",
       "                                              Skills Qualification  \\\n",
       "0                            [Patient Care, Nursing]           NaN   \n",
       "1  [Global Marketing, Integrated Marketing, Field...           NaN   \n",
       "2                                                NaN           NaN   \n",
       "3  [c, VOIP, Cisco, MS Office tools, Genesys, SIP...           NaN   \n",
       "4                                                NaN           NaN   \n",
       "\n",
       "            City          State  Zipcode Job Opening Date Job Closing Date  \\\n",
       "0    Charlestown  Massachusetts   2129.0       2021-07-13              NaN   \n",
       "1    Westborough  Massachusetts   1581.0       2021-08-03              NaN   \n",
       "2  North Andover  Massachusetts   1845.0       2021-09-08       2021-09-28   \n",
       "3     Dorchester  Massachusetts   2121.0       2021-08-31       2021-09-16   \n",
       "4    Marlborough  Massachusetts   1752.0       2021-09-11              NaN   \n",
       "\n",
       "   Status                     Website Url  \n",
       "0    OPEN  http://partnersurgentcare.org/  \n",
       "1    OPEN          http://www.danaher.com  \n",
       "2  CLOSED  www.brightviewseniorliving.com  \n",
       "3  CLOSED     http://www.softworldinc.com  \n",
       "4    OPEN           http://www.artech.com  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18862 entries, 0 to 18861\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Job Id            18862 non-null  object \n",
      " 1   Job Title         18862 non-null  object \n",
      " 2   SOC Code          18862 non-null  object \n",
      " 3   Job Description   18781 non-null  object \n",
      " 4   Company Name      18862 non-null  object \n",
      " 5   Skills            14268 non-null  object \n",
      " 6   Qualification     6438 non-null   object \n",
      " 7   City              18807 non-null  object \n",
      " 8   State             18862 non-null  object \n",
      " 9   Zipcode           18806 non-null  float64\n",
      " 10  Job Opening Date  18862 non-null  object \n",
      " 11  Job Closing Date  6880 non-null   object \n",
      " 12  Status            18862 non-null  object \n",
      " 13  Website Url       18862 non-null  object \n",
      "dtypes: float64(1), object(13)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get information about the dataset (e.g., data types, missing values)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job Id                  0\n",
       "Job Title               0\n",
       "SOC Code                0\n",
       "Job Description        81\n",
       "Company Name            0\n",
       "Skills               4594\n",
       "Qualification       12424\n",
       "City                   55\n",
       "State                   0\n",
       "Zipcode                56\n",
       "Job Opening Date        0\n",
       "Job Closing Date    11982\n",
       "Status                  0\n",
       "Website Url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to fill missing values in \"City\" column, first, I checked Zipcodes but it was also missing. So, I decided the fill missing values with mode of \"City\". Since all of the jobs were in Massachusetts.\n",
    "data[\"City\"]=data[\"City\"].fillna(data['City'].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a condition for filling missing values in column Job Description\n",
    "condition=(data[\"Job Description\"].isnull()) & (data[\"Skills\"].notnull())\n",
    "# Filling missing Job Description column values with \"Job Title\" and \"Skills\" (if \"Skills\" columns is present)\n",
    "data.loc[condition, \"Job Description\"] = data[\"Job Title\"]+\", \"+data[\"Skills\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If \"Skills\" column is not present drop the missing values in the \"Job Description\"(drop rows)\n",
    "data.dropna(subset=[\"Job Description\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean and preprocess text\n",
    "def clean_and_preprocess_text(text):\n",
    "    # 1. Remove HTML tags\n",
    "    CLEANR = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    text = re.sub(CLEANR, '', text)\n",
    "\n",
    "    # 2. Remove links\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    text=url.sub(r'',text)\n",
    "\n",
    "    # 3. Remove special characters, punctuation, and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # 4. Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # 5. Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # 6. Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # 7. Stemming \n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "    # 8. Join tokens back into text\n",
    "    cleaned_text = ' '.join(stemmed_tokens)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# Clean and preprocess the original Job Description\n",
    "data['Job Description'] = data['Job Description'].apply(clean_and_preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty values after cleaning the text\n",
    "data=data[data[\"Job Description\"]!=\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging \"City\" and \"State\" columns into one column\n",
    "data[\"Location\"]=data[\"City\"]+\"/\"+data[\"State\"]\n",
    "#Renaming columns according to project requirements.\n",
    "data=data.rename(columns={\"Job Opening Date\":\"Posting_Date\",\"Website Url\":\"Source\",\"Job Description\":\"Job_Description\",\"Job Title\":\"Job_Title\",\"Company Name\":\"Company_Name\",\"Job Id\":\"Job_Id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[[\"Job_Id\",\"Job_Title\",\"Job_Description\",\"Company_Name\",\"Location\",\"Posting_Date\",\"Source\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18847 entries, 0 to 18861\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Job_Id           18847 non-null  object\n",
      " 1   Job_Title        18847 non-null  object\n",
      " 2   Job_Description  18847 non-null  object\n",
      " 3   Company_Name     18847 non-null  object\n",
      " 4   Location         18847 non-null  object\n",
      " 5   Posting_Date     18847 non-null  object\n",
      " 6   Source           18847 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generating Embeddings\n",
    "To capture the semantic and contextual information within text data, I utilized the \"paraphrase-MiniLM-L6-v2\" model. This choice was made because Sentence-BERT models, like \"paraphrase-MiniLM-L6-v2,\" are explicitly designed for generating sentence embeddings and excelling in tasks related to sentence similarity. This particular model, which is built upon the efficient MiniLM architecture, offers strong performance on various sentence similarity tasks while maintaining computational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    # Set the device to CUDA\n",
    "    print(\"using GPU\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    # Use CPU if CUDA is not available\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Load the SBERT model with the specified device\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-MiniLM-L6-v2', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SBERT to the 'Job Description' column and store the embeddings in a new column\n",
    "data['job_description_embeddings'] = data['Job_Description'].apply(lambda x: model.encode(x, convert_to_tensor=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Implementing Milvus for Duplicate Detection\n",
    "\n",
    "In this section, I have successfully set up a Milvus instance and performed data insertion, specifically for the Job_Id, Job_Title, and job_description_embeddings columns. Subsequently, I implemented a duplicate search function.\n",
    "\n",
    "I utilized the L2 parameter to compute the distance between text embeddings, and I set the threshold parameter to 1, aiming to identify absolute duplicates. It's worth noting that this threshold can be adjusted if we desire to capture near-duplicates as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "\n",
    "# Connect to a server\n",
    "connections.connect(host='localhost', port='19530')\n",
    "\n",
    "# Create collection, insert data and build index\n",
    "def create_milvus_collection(collection_name, dim):\n",
    "    if utility.has_collection(collection_name):\n",
    "        utility.drop_collection(collection_name)\n",
    "    \n",
    "    fields = [\n",
    "            FieldSchema(name=\"Job_Id\", dtype=DataType.VARCHAR, is_primary=True, auto_id=False,max_length=500),\n",
    "            # FieldSchema(name=\"Job_Description\",dtype=DataType.VARCHAR,max_length=50000),\n",
    "            FieldSchema(name=\"Job_Title\",dtype=DataType.VARCHAR,max_length=50000),\n",
    "            # FieldSchema(name=\"Company_Name\",dtype=DataType.VARCHAR,max_length=50000),\n",
    "            # FieldSchema(name=\"Location\",dtype=DataType.VARCHAR,max_length=50000),\n",
    "            # FieldSchema(name=\"Posting_Date\",dtype=DataType.VARCHAR,max_length=50000),\n",
    "            # FieldSchema(name=\"Source\",dtype=DataType.VARCHAR,max_length=50000),\n",
    "            FieldSchema(name=\"job_description_embeddings\", dtype=DataType.FLOAT_VECTOR, dim=dim),\n",
    "\n",
    "    ]\n",
    "    schema = CollectionSchema(fields=fields, description='search duplicate text')\n",
    "    collection = Collection(name=collection_name, schema=schema)\n",
    "\n",
    "    # Inserting the data in smaller batches in order to avoid grpc rpcerror \n",
    "    batch_size=20000\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        print(i+batch_size)\n",
    "        job_ids = [j_id for j_id in data[\"Job_Id\"].to_list()[i:i+batch_size]]\n",
    "        job_titles = [j_title for j_title in data[\"Job_Title\"].to_list()[i:i+batch_size]]\n",
    "        embeds1 = [embed.cpu().numpy() for embed in data[\"job_description_embeddings\"].to_list()[i:i+batch_size]]\n",
    "        collection.insert([job_ids,job_titles,embeds1])\n",
    "\n",
    "    # After final collection is inserted, it is best to call flush to have no growing segments left in memory\n",
    "    collection.flush()\n",
    "\n",
    "    index_params = {\n",
    "        'metric_type': \"L2\",\n",
    "        'index_type': \"IVF_FLAT\",\n",
    "        'params': {\"nlist\": 2048}\n",
    "    }\n",
    "    collection.create_index(field_name='job_description_embeddings', index_params=index_params)\n",
    "    return collection\n",
    "\n",
    "collection = create_milvus_collection('search_duplicate', len(data[\"job_description_embeddings\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s]\n"
     ]
    }
   ],
   "source": [
    "def search_for_duplicates(query_embedding, threshold=1):\n",
    "    connections.connect(host=\"localhost\",port=\"19530\")\n",
    "    search_clause = query_embedding.lower()\n",
    "    search_encode = [list(i) for i in model.encode([search_clause])]\n",
    "    collection = Collection('search_duplicate')\n",
    "    collection.load()\n",
    "    documents = collection.search(data=search_encode, anns_field=\"job_description_embeddings\", param={\"metric\":\"L2\"},\n",
    "                    output_fields=[\"Job_Id\",\"Job_Title\"], limit=100)\n",
    "    distance,job_id,title=[],[],[]\n",
    "    # Filter results based on the similarity threshold\n",
    "    for values in documents:\n",
    "        for doc in values:\n",
    "            if doc.distance<threshold:\n",
    "                distance.append(doc.distance)\n",
    "                job_id.append(doc.id)\n",
    "                title.append(doc.entity._row_data[\"Job_Title\"])\n",
    "    # Filter results based on the similarity threshold\n",
    "\n",
    "    dict = {'job_id': job_id, 'Job_Title': title, 'distance': distance} \n",
    "    \n",
    "    df = pd.DataFrame(dict)\n",
    "    collection.release()\n",
    "\n",
    "    return df\n",
    "    \n",
    "\n",
    "\n",
    "df= search_for_duplicates(data[\"Job_Description\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3cb6552225decf057254975fb34b74a2</td>\n",
       "      <td>Patient Care Associate (CNA), 24 hrs, Nights</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a868b63df4241cfa47e340b20db8f3a6</td>\n",
       "      <td>Patient Care Associate, 24 hrs/wk, Night Shift...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f32455780a2f1a798a9d088eea671858</td>\n",
       "      <td>Patient Care Associate (CNA), 32 hrs, Nights</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6d73552246ba49b2472dd6699d1ab8c8</td>\n",
       "      <td>Patient Care Associate, 32 hrs/wk, Day Shift, ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c2a1023d48a0d466733ef3817741f6ad</td>\n",
       "      <td>Patient Care Associate, 40 hrs/wk, Day Shift, ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>660d47be5c2db28218b65ad0df9965a2</td>\n",
       "      <td>Patient Care Associate, 32 hrs/wk, Night Shift...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a7c10d77ac266f048f5c0f21fc4230e0</td>\n",
       "      <td>Patient Care Associate, 32 hrs/wk, Day Shift, ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>e00c0266c03266fe4e60202b38cae3e2</td>\n",
       "      <td>Patient Care Associate (CNA) - Overnight Shift...</td>\n",
       "      <td>0.335985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>d0bfecf7a00eb06752db57af8bd9e631</td>\n",
       "      <td>Patient Care Associate (CNA) - Evening Shift -...</td>\n",
       "      <td>0.335985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f23f5e109e557063b19241c73eb356a</td>\n",
       "      <td>Patient Care Associate, 32 Hour Day Rotating S...</td>\n",
       "      <td>0.414922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             job_id  \\\n",
       "0  3cb6552225decf057254975fb34b74a2   \n",
       "1  a868b63df4241cfa47e340b20db8f3a6   \n",
       "2  f32455780a2f1a798a9d088eea671858   \n",
       "3  6d73552246ba49b2472dd6699d1ab8c8   \n",
       "4  c2a1023d48a0d466733ef3817741f6ad   \n",
       "5  660d47be5c2db28218b65ad0df9965a2   \n",
       "6  a7c10d77ac266f048f5c0f21fc4230e0   \n",
       "7  e00c0266c03266fe4e60202b38cae3e2   \n",
       "8  d0bfecf7a00eb06752db57af8bd9e631   \n",
       "9   f23f5e109e557063b19241c73eb356a   \n",
       "\n",
       "                                           Job_Title  distance  \n",
       "0       Patient Care Associate (CNA), 24 hrs, Nights  0.000000  \n",
       "1  Patient Care Associate, 24 hrs/wk, Night Shift...  0.000000  \n",
       "2       Patient Care Associate (CNA), 32 hrs, Nights  0.000000  \n",
       "3  Patient Care Associate, 32 hrs/wk, Day Shift, ...  0.000000  \n",
       "4  Patient Care Associate, 40 hrs/wk, Day Shift, ...  0.000000  \n",
       "5  Patient Care Associate, 32 hrs/wk, Night Shift...  0.000000  \n",
       "6  Patient Care Associate, 32 hrs/wk, Day Shift, ...  0.000000  \n",
       "7  Patient Care Associate (CNA) - Overnight Shift...  0.335985  \n",
       "8  Patient Care Associate (CNA) - Evening Shift -...  0.335985  \n",
       "9  Patient Care Associate, 32 Hour Day Rotating S...  0.414922  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
